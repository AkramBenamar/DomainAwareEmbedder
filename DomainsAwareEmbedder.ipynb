{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "teAiP6IL6iN4"
      ],
      "authorship_tag": "ABX9TyM07fDnbTQhm49d/rg5JYI4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "910f995a18bb4d7ab8a926676c08f978": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d67306189eb5486ba981ed8423dff2cb",
              "IPY_MODEL_bc520cc9762b49e58530e292b7b7bb56",
              "IPY_MODEL_0dedc21ba217431dbcbf4f055ca4dfc5"
            ],
            "layout": "IPY_MODEL_1f042fa3434744229abfef51d29b3234"
          }
        },
        "d67306189eb5486ba981ed8423dff2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7263a034ba5041dabad0029237b3517a",
            "placeholder": "​",
            "style": "IPY_MODEL_45412af024f446caa0dea9fdfbaa3172",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "bc520cc9762b49e58530e292b7b7bb56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2379f7a484bd4862b61e17ff3ccb7954",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aced003b8a6f4bdfa820f8936fa3cbda",
            "value": 49
          }
        },
        "0dedc21ba217431dbcbf4f055ca4dfc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9db3ac5a4e14647aa88d0a82fa479c8",
            "placeholder": "​",
            "style": "IPY_MODEL_22ec881b725f40b4a4b305807c540d70",
            "value": " 49.0/49.0 [00:00&lt;00:00, 950B/s]"
          }
        },
        "1f042fa3434744229abfef51d29b3234": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7263a034ba5041dabad0029237b3517a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45412af024f446caa0dea9fdfbaa3172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2379f7a484bd4862b61e17ff3ccb7954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aced003b8a6f4bdfa820f8936fa3cbda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9db3ac5a4e14647aa88d0a82fa479c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22ec881b725f40b4a4b305807c540d70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "083d83e70fac41e4919ec50d3f3128d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_95e2fe0240214f6db8090a3365360391",
              "IPY_MODEL_1e1e3f90e3bb45b787f9bb19ada0de04",
              "IPY_MODEL_e29831df898d4d0289f8b6478a3f5480"
            ],
            "layout": "IPY_MODEL_c4c5cf08de144023b1a7224b1ab004a9"
          }
        },
        "95e2fe0240214f6db8090a3365360391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df1542299633409db9317c1d4f0d9652",
            "placeholder": "​",
            "style": "IPY_MODEL_149347d26a924312baf1206f3bb01f0c",
            "value": "config.json: 100%"
          }
        },
        "1e1e3f90e3bb45b787f9bb19ada0de04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bed83d4ff29e45c688b379ba1955c2b7",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a23b708a0c24495688e8a387debedbb0",
            "value": 625
          }
        },
        "e29831df898d4d0289f8b6478a3f5480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a285270f74b54da5a2afd0da955462c7",
            "placeholder": "​",
            "style": "IPY_MODEL_eedbd7ee754d4844a9b13debe84f04a1",
            "value": " 625/625 [00:00&lt;00:00, 23.0kB/s]"
          }
        },
        "c4c5cf08de144023b1a7224b1ab004a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1542299633409db9317c1d4f0d9652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "149347d26a924312baf1206f3bb01f0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bed83d4ff29e45c688b379ba1955c2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a23b708a0c24495688e8a387debedbb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a285270f74b54da5a2afd0da955462c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eedbd7ee754d4844a9b13debe84f04a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b449615c3224f7faf45f9fa307f00e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d75319594725400cb0a78161e7e924b8",
              "IPY_MODEL_0e7ce4ef0ee04609b124159ccb0ae5f0",
              "IPY_MODEL_f32ead801e484a4bbbff14fdb649640f"
            ],
            "layout": "IPY_MODEL_f0a713073db84971a76813cbd450809b"
          }
        },
        "d75319594725400cb0a78161e7e924b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2be68db401143ca94459a62d03bf68e",
            "placeholder": "​",
            "style": "IPY_MODEL_62fae1f6da9b463fbcccbb3b8950477a",
            "value": "vocab.txt: 100%"
          }
        },
        "0e7ce4ef0ee04609b124159ccb0ae5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2340c95fb0c948bdb2a98de44ec6b0ea",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd106d03b4104839b02f68c330e934f0",
            "value": 995526
          }
        },
        "f32ead801e484a4bbbff14fdb649640f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afbe97b551654d04a816ff5c899b3cef",
            "placeholder": "​",
            "style": "IPY_MODEL_0d6353ec3fb0493dbe0821cbddc7bb10",
            "value": " 996k/996k [00:00&lt;00:00, 5.30MB/s]"
          }
        },
        "f0a713073db84971a76813cbd450809b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2be68db401143ca94459a62d03bf68e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62fae1f6da9b463fbcccbb3b8950477a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2340c95fb0c948bdb2a98de44ec6b0ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd106d03b4104839b02f68c330e934f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afbe97b551654d04a816ff5c899b3cef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d6353ec3fb0493dbe0821cbddc7bb10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a58e5427079c4c67a344b26337c3c227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c86272b0208e42d9bbce9d14c6f64875",
              "IPY_MODEL_168e77ae27b147f39034b8dfadec951d",
              "IPY_MODEL_76258b2062b44793bd4f83cd73999466"
            ],
            "layout": "IPY_MODEL_88242159bb734ab49cb4d02d6717be41"
          }
        },
        "c86272b0208e42d9bbce9d14c6f64875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d0aae2bdd5648aca100fcbbfc0c7832",
            "placeholder": "​",
            "style": "IPY_MODEL_f0b3566a08b2413dab305c06211390c1",
            "value": "tokenizer.json: 100%"
          }
        },
        "168e77ae27b147f39034b8dfadec951d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5991c0e35d56449aae9167e26455593b",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac1cfe6d12cb4ce6bb28c0cc114f453d",
            "value": 1961828
          }
        },
        "76258b2062b44793bd4f83cd73999466": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06df3b27bc04475fbbafc67b877a2834",
            "placeholder": "​",
            "style": "IPY_MODEL_3bf0fd1e4b7b4658ad56eab175539d0c",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 8.36MB/s]"
          }
        },
        "88242159bb734ab49cb4d02d6717be41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d0aae2bdd5648aca100fcbbfc0c7832": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0b3566a08b2413dab305c06211390c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5991c0e35d56449aae9167e26455593b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac1cfe6d12cb4ce6bb28c0cc114f453d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06df3b27bc04475fbbafc67b877a2834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bf0fd1e4b7b4658ad56eab175539d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkramBenamar/DomainAwareEmbedder/blob/master/DomainsAwareEmbedder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DomainsAwareEmbeder"
      ],
      "metadata": {
        "id": "RTNhO5mLwicL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "4K77qXJTwrao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Embedder"
      ],
      "metadata": {
        "id": "DPr1X5sDw_Ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####PositionalEncoding"
      ],
      "metadata": {
        "id": "qnq6iHrYzEhb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkc-sBQVUZCI",
        "outputId": "1d1a9835-62c1-46cf-8600-6264d9b7faa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "....\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 0.018s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=4 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import unittest\n",
        "import torch\n",
        "import math\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 512) -> None:\n",
        "        super().__init__()\n",
        "        self.pe = self._generate_encoding(d_model, max_len)\n",
        "\n",
        "    def _generate_encoding(self, d_model: int, max_len: int) -> torch.Tensor:\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        return pe.unsqueeze(0)  # (1, max_len, d_model)\n",
        "\n",
        "    def forward(self, seq_len: int) -> torch.Tensor:\n",
        "        return self.pe[:, :seq_len]\n",
        "\n",
        "class TestPositionalEncoding(unittest.TestCase):\n",
        "\n",
        "    def test_shape(self):\n",
        "        \"\"\"Test output shape\"\"\"\n",
        "        d_model = 16\n",
        "        max_len = 100\n",
        "        pe = PositionalEncoding(d_model, max_len)\n",
        "        output = pe(50)\n",
        "        self.assertEqual(output.shape, (1, 50, d_model))\n",
        "\n",
        "    def test_values_repeatability(self):\n",
        "        \"\"\"Test same output for same inputs\"\"\"\n",
        "        d_model = 32\n",
        "        max_len = 60\n",
        "        pe = PositionalEncoding(d_model, max_len)\n",
        "        output1 = pe(10)\n",
        "        output2 = pe(10)\n",
        "        self.assertTrue(torch.allclose(output1, output2, atol=1e-6))\n",
        "\n",
        "    def test_no_nan(self):\n",
        "        \"\"\"Test qnot NaN\"\"\"\n",
        "        pe = PositionalEncoding(64, 128)\n",
        "        output = pe(64)\n",
        "        self.assertFalse(torch.isnan(output).any())\n",
        "\n",
        "    def test_known_value(self):\n",
        "        \"\"\"Test values\"\"\"\n",
        "        d_model = 4\n",
        "        max_len = 1\n",
        "        pe = PositionalEncoding(d_model, max_len)\n",
        "        output = pe(1)[0, 0]  # shape: (d_model,)\n",
        "        expected = torch.tensor([\n",
        "            math.sin(0 / (10000 ** (0 / d_model))),  # sin(0) = 0\n",
        "            math.cos(0 / (10000 ** (0 / d_model))),  # cos(0) = 1\n",
        "            math.sin(0 / (10000 ** (2 / d_model))),  # sin(0) = 0\n",
        "            math.cos(0 / (10000 ** (2 / d_model)))   # cos(0) = 1\n",
        "        ])\n",
        "        self.assertTrue(torch.allclose(output, expected, atol=1e-5))\n",
        "\n",
        "\n",
        "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestPositionalEncoding))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Attention"
      ],
      "metadata": {
        "id": "eQKbD8OLPWYO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DomainEmbedder"
      ],
      "metadata": {
        "id": "c2CcV66P4oU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "import torch\n",
        "\n",
        "class DomainAwareEmbedder(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_domains: int,\n",
        "        d_model: int, #hidden_dim for the entire model\n",
        "        d_embed: int, #Inpput dim embedding\n",
        "        n_heads: int = 1,\n",
        "        max_seq_len: int = 512\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "\n",
        "        self.domain_proj_layer = nn.Linear(num_domains, d_model) #d_k d_v\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_seq_len)\n",
        "        self.query_proj = nn.Linear(d_embed, d_model) #d_q\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=n_heads, batch_first=True)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "\n",
        "    def project_domains(self, m: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Project modality descriptors to embedding space.\"\"\"\n",
        "        return self.domain_proj_layer(m.float())\n",
        "\n",
        "    def combine_domain_and_position(self, domain_proj: torch.Tensor, seq_len: int, device=None) -> torch.Tensor:\n",
        "        \"\"\"Add positional encoding to projected modality embeddings.\"\"\"\n",
        "        pos_enc = self.pos_encoder(seq_len).to(device or domain_proj.device)\n",
        "        return domain_proj + pos_enc\n",
        "\n",
        "    def forward(self, x: torch.Tensor, m: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: (batch_size, seq_len, d_embed)\n",
        "            m: (batch_size, seq_len, num_domains)\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, seq_len, d_model)\n",
        "        \"\"\"\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "        # print(f\"x shape: {x.shape}\")\n",
        "        # print(f\"m shape: {m.shape}\")\n",
        "        domain_proj = self.project_domains(m)\n",
        "        DC = self.combine_domain_and_position(domain_proj, seq_len)\n",
        "\n",
        "        query = self.query_proj(x)\n",
        "        # print(f\"query shape: {query.shape}\")\n",
        "        # print(f\"key and value shape: {DC.shape}\")\n",
        "        attended, scores = self.attention(query, DC, DC)\n",
        "        # print(f\"attended shape: {attended.shape}\")\n",
        "\n",
        "\n",
        "        return self.layer_norm(attended)\n",
        "\n",
        "\n",
        "\n",
        "class TestDomainAwareEmbedder(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        self.batch_size = 2\n",
        "        self.seq_len = 10\n",
        "        self.d_embed = 32\n",
        "        self.d_model = 1\n",
        "        self.num_domains = 3\n",
        "\n",
        "        self.model = DomainAwareEmbedder(\n",
        "            num_domains=self.num_domains,\n",
        "            d_model=self.d_model,\n",
        "            d_embed=self.d_embed,\n",
        "            n_heads=1,\n",
        "            max_seq_len=100\n",
        "        )\n",
        "\n",
        "        self.x = torch.randn(self.batch_size, self.seq_len, self.d_embed)\n",
        "        self.m = torch.randn(self.batch_size, self.seq_len, self.num_domains)\n",
        "\n",
        "    def test_project_domains(self):\n",
        "        projected = self.model.project_domains(self.m)\n",
        "        self.assertEqual(projected.shape, (self.batch_size, self.seq_len, self.d_model))\n",
        "        self.assertFalse(torch.isnan(projected).any())\n",
        "\n",
        "    def test_combine_domain_and_position(self):\n",
        "        domain_proj = self.model.project_domains(self.m)\n",
        "        combined = self.model.combine_domain_and_position(domain_proj, self.seq_len)\n",
        "        self.assertEqual(combined.shape, (self.batch_size, self.seq_len, self.d_model))\n",
        "        self.assertFalse(torch.isnan(combined).any())\n",
        "\n",
        "    def test_forward_output_shape(self):\n",
        "        output = self.model(self.x, self.m)\n",
        "        self.assertEqual(output.shape, (self.batch_size, self.seq_len, self.d_model))\n",
        "\n",
        "    def test_forward_repeatability(self):\n",
        "        output1 = self.model(self.x, self.m)\n",
        "        output2 = self.model(self.x, self.m)\n",
        "        self.assertTrue(torch.allclose(output1, output2, atol=1e-5))\n",
        "\n",
        "    def test_forward_no_nan(self):\n",
        "        output = self.model(self.x, self.m)\n",
        "        self.assertFalse(torch.isnan(output).any())\n",
        "\n",
        "    def test_combine_domain_and_position_adds_encoding(self):\n",
        "        domain_proj = self.model.project_domains(self.m)\n",
        "        combined = self.model.combine_domain_and_position(domain_proj, self.seq_len)\n",
        "        pos_enc = self.model.pos_encoder(self.seq_len).to(domain_proj.device)\n",
        "        diff = combined - domain_proj\n",
        "        self.assertTrue(torch.allclose(diff, pos_enc.expand_as(domain_proj), atol=1e-6))\n",
        "    def test_positional_encoding_applied_per_position(self):\n",
        "        domain_proj = self.model.project_domains(self.m)\n",
        "        combined = self.model.combine_domain_and_position(domain_proj, self.seq_len)\n",
        "        pos_enc = self.model.pos_encoder(self.seq_len).to(domain_proj.device)  # shape: (1, seq_len, d_model)\n",
        "\n",
        "        for b in range(self.batch_size):\n",
        "            for i in range(self.seq_len):\n",
        "                expected = domain_proj[b, i, :] + pos_enc[0, i, :]\n",
        "                actual = combined[b, i, :]\n",
        "                self.assertTrue(torch.allclose(actual, expected, atol=1e-6),\n",
        "                                msg=f\"Incorrect positional encoding at batch {b}, position {i}\")\n",
        "\n",
        "\n",
        "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestDomainAwareEmbedder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTshFxgU2vrz",
        "outputId": "c1f134b8-6352-485b-83d2-12cf6f53619d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".......\n",
            "----------------------------------------------------------------------\n",
            "Ran 7 tests in 0.077s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=7 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Encoder"
      ],
      "metadata": {
        "id": "zZ1QZTnZxCiR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####TransformerEncoder"
      ],
      "metadata": {
        "id": "teAiP6IL6iN4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import unittest\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    \"\"\"Transformer-based encoder\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int,\n",
        "        n_heads: int = 4,\n",
        "        n_layers: int = 2,\n",
        "        dropout: float = 0.1\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim,\n",
        "            nhead=n_heads,\n",
        "            dim_feedforward=hidden_dim * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer,\n",
        "            num_layers=n_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape (batch_size, seq_len, input_dim)\n",
        "        Returns:\n",
        "            Output tensor of shape (batch_size, hidden_dim), last token representation\n",
        "        \"\"\"\n",
        "        x = self.input_proj(x)\n",
        "        out = self.transformer_encoder(x)\n",
        "        return out[:, -1, :]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TestTransformerEncoder(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        self.batch_size = 4\n",
        "        self.seq_len = 10\n",
        "        self.input_dim = 32\n",
        "        self.hidden_dim = 64\n",
        "        self.encoder = TransformerEncoder(\n",
        "            input_dim=self.input_dim,\n",
        "            hidden_dim=self.hidden_dim,\n",
        "            n_heads=4,\n",
        "            n_layers=2\n",
        "        )\n",
        "\n",
        "    def test_output_shape(self):\n",
        "        x = torch.randn(self.batch_size, self.seq_len, self.input_dim)\n",
        "        out = self.encoder(x)\n",
        "        self.assertEqual(out.shape, (self.batch_size, self.hidden_dim))\n",
        "\n",
        "    def test_projection_works(self):\n",
        "        x = torch.randn(self.batch_size, self.seq_len, self.input_dim)\n",
        "        projected = self.encoder.input_proj(x)\n",
        "        self.assertEqual(projected.shape, (self.batch_size, self.seq_len, self.hidden_dim))\n",
        "\n",
        "    def test_determinism(self):\n",
        "        torch.manual_seed(42)\n",
        "        self.encoder.eval()\n",
        "        x = torch.randn(self.batch_size, self.seq_len, self.input_dim)\n",
        "        out1 = self.encoder(x)\n",
        "        torch.manual_seed(42)\n",
        "        out2 = self.encoder(x)\n",
        "        self.assertTrue(torch.allclose(out1, out2, atol=1e-6))\n",
        "\n",
        "\n",
        "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestTransformerEncoder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfvx8SQD6p8w",
        "outputId": "5fd348c1-703c-40e1-c0b7-caccfc3915d8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "...\n",
            "----------------------------------------------------------------------\n",
            "Ran 3 tests in 0.060s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=3 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DomainAwareTransformerEncoder"
      ],
      "metadata": {
        "id": "UdiUvId391Bd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNQKaqIpBHYJ",
        "outputId": "f0379380-dfc3-4807-a450-d53438d49cbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchinfo\n",
            "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
            "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: torchinfo\n",
            "Successfully installed torchinfo-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import unittest\n",
        "import pandas as pd\n",
        "from torchinfo import summary\n",
        "\n",
        "\n",
        "class DomainAwareTransformerEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Encoder integrates domain-aware embeddings with a TransformerEncoder.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_domains: int,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int,\n",
        "        domain_embed_dim: int=1,\n",
        "        max_seq_len: int = 512,\n",
        "        n_heads: int = 1,\n",
        "        n_heads_transformer: int = 4,\n",
        "        n_layers: int = 2,\n",
        "        dropout: float = 0.1,\n",
        "        num_classes: int = 31,\n",
        "        vocab_size: int = 119547,\n",
        "        inject_domain_bias: bool = True,\n",
        "        use_attention_fusion: bool = True\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.inject_domain_bias = inject_domain_bias\n",
        "        self.use_attention_fusion = use_attention_fusion\n",
        "\n",
        "        if self.inject_domain_bias == True:\n",
        "            self.domain_embedder = DomainAwareEmbedder(\n",
        "                num_domains=num_domains,\n",
        "                d_model=domain_embed_dim, #Correspond to dq dk dv, and result vector dim\n",
        "                d_embed=input_dim,  #embeding dim\n",
        "                n_heads=n_heads,\n",
        "                max_seq_len=max_seq_len\n",
        "            )\n",
        "            if self.use_attention_fusion == True:\n",
        "                self.domain_upsample = nn.Linear(domain_embed_dim, hidden_dim)\n",
        "                self.fusion_attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=1, batch_first=True)\n",
        "\n",
        "        self.encoder = TransformerEncoder(\n",
        "            input_dim=hidden_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            n_heads=n_heads_transformer,\n",
        "            n_layers=n_layers,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.embedding = nn.Embedding(vocab_size, input_dim)\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
        "\n",
        "    def forward(self, x: torch.LongTensor, m: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input features of shape (batch_size, seq_len, input_dim)\n",
        "            m: Domain descriptors of shape (batch_size, seq_len, num_domains)\n",
        "        Returns:\n",
        "            Tensor of shape (batch_size, hidden_dim), last token representation\n",
        "        \"\"\"\n",
        "        # skip conn\n",
        "\n",
        "        x = self.embedding(x)  #(B,S,input_dim)\n",
        "        x_proj = self.input_proj(x)  # (B, S, hidden_dim)\n",
        "\n",
        "        if self.inject_domain_bias == True:\n",
        "\n",
        "          domain_context = self.domain_embedder(x, m)  # (B, S, domain_embed_dim)\n",
        "          if self.use_attention_fusion == True:\n",
        "            domain_context = self.domain_upsample(domain_context)\n",
        "            enriched, scores = self.fusion_attention(x_proj, domain_context, domain_context)\n",
        "\n",
        "\n",
        "          else:\n",
        "            enriched = x_proj + domain_context  # Inject domain bias\n",
        "\n",
        "        else:\n",
        "            enriched = x_proj\n",
        "\n",
        "        enc= self.encoder(enriched)\n",
        "\n",
        "        return self.classifier(enc)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class TestDomainAwareTransformerEncoder(unittest.TestCase):\n",
        "\n",
        "    def setUp(self):\n",
        "        self.batch_size = 2\n",
        "        self.seq_len = 10\n",
        "        self.input_dim = 32\n",
        "        self.hidden_dim = 64\n",
        "        self.domain_embed_dim = 2\n",
        "        self.num_domains = 5\n",
        "        self.num_classes=31\n",
        "\n",
        "        self.model = DomainAwareTransformerEncoder(\n",
        "            num_domains=self.num_domains,\n",
        "            input_dim=self.input_dim,\n",
        "            hidden_dim=self.hidden_dim,\n",
        "            domain_embed_dim=self.domain_embed_dim,\n",
        "            max_seq_len=50,\n",
        "            use_attention_fusion=True\n",
        "        )\n",
        "\n",
        "        self.x = torch.randint(0, 35222, (self.batch_size, self.seq_len), dtype=torch.long)\n",
        "        self.m = torch.randn(self.batch_size, self.seq_len, self.num_domains)\n",
        "\n",
        "    def test_output_shape(self):\n",
        "        out = self.model(self.x, self.m)\n",
        "\n",
        "        self.assertEqual(out.shape, (self.batch_size, self.num_classes))\n",
        "\n",
        "    def test_embedder_parameters_are_trainable(self):\n",
        "        embedder_params = list(self.model.domain_embedder.parameters())\n",
        "        self.assertTrue(any(p.requires_grad for p in embedder_params))\n",
        "        self.assertTrue(any(p.numel() > 0 for p in embedder_params))\n",
        "\n",
        "    def test_deterministic_output(self):\n",
        "        torch.manual_seed(42)\n",
        "        out1 = self.model(self.x, self.m)\n",
        "        torch.manual_seed(42)\n",
        "        out2 = self.model(self.x, self.m)\n",
        "        self.assertTrue(torch.allclose(out1, out2, atol=1e-5))\n",
        "\n",
        "    def test_total_trainable_params(self):\n",
        "        total_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "        self.assertGreater(total_params, 0)\n",
        "\n",
        "    def test_visualize_parameters(self):\n",
        "        model = self.model\n",
        "        batch_size = 2\n",
        "        seq_len = 10\n",
        "        input_dim = 32\n",
        "        num_domains = 5\n",
        "\n",
        "        summary(\n",
        "            model,\n",
        "            input_data=(torch.randint(0, 30522, (self.batch_size, self.seq_len), dtype=torch.long),\n",
        "                        torch.randn(batch_size, seq_len, num_domains)),\n",
        "            col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "            depth=4,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "unittest.TextTestRunner().run(unittest.TestLoader().loadTestsFromTestCase(TestDomainAwareTransformerEncoder))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcK3Xzq197JS",
        "outputId": "261b365e-3efb-4217-988b-a9866d1cf5df"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".....\n",
            "----------------------------------------------------------------------\n",
            "Ran 5 tests in 0.368s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================================================================================================\n",
            "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #                   Trainable\n",
            "======================================================================================================================================================\n",
            "DomainAwareTransformerEncoder                      [2, 10]                   [2, 31]                   --                        True\n",
            "├─Embedding: 1-1                                   [2, 10]                   [2, 10, 32]               3,825,504                 True\n",
            "├─Linear: 1-2                                      [2, 10, 32]               [2, 10, 64]               2,112                     True\n",
            "├─DomainAwareEmbedder: 1-3                         [2, 10, 32]               [2, 10, 2]                --                        True\n",
            "│    └─Linear: 2-1                                 [2, 10, 5]                [2, 10, 2]                12                        True\n",
            "│    └─PositionalEncoding: 2-2                     --                        [1, 10, 2]                --                        --\n",
            "│    └─Linear: 2-3                                 [2, 10, 32]               [2, 10, 2]                66                        True\n",
            "│    └─MultiheadAttention: 2-4                     [2, 10, 2]                [2, 10, 2]                24                        True\n",
            "│    └─LayerNorm: 2-5                              [2, 10, 2]                [2, 10, 2]                4                         True\n",
            "├─Linear: 1-4                                      [2, 10, 2]                [2, 10, 64]               192                       True\n",
            "├─MultiheadAttention: 1-5                          [2, 10, 64]               [2, 10, 64]               16,640                    True\n",
            "├─TransformerEncoder: 1-6                          [2, 10, 64]               [2, 64]                   --                        True\n",
            "│    └─Linear: 2-6                                 [2, 10, 64]               [2, 10, 64]               4,160                     True\n",
            "│    └─TransformerEncoder: 2-7                     [2, 10, 64]               [2, 10, 64]               --                        True\n",
            "│    │    └─ModuleList: 3-1                        --                        --                        --                        True\n",
            "│    │    │    └─TransformerEncoderLayer: 4-1      [2, 10, 64]               [2, 10, 64]               49,984                    True\n",
            "│    │    │    └─TransformerEncoderLayer: 4-2      [2, 10, 64]               [2, 10, 64]               49,984                    True\n",
            "├─Linear: 1-7                                      [2, 64]                   [2, 31]                   2,015                     True\n",
            "======================================================================================================================================================\n",
            "Total params: 3,950,697\n",
            "Trainable params: 3,950,697\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (Units.MEGABYTES): 7.80\n",
            "======================================================================================================================================================\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.18\n",
            "Params size (MB): 15.60\n",
            "Estimated Total Size (MB): 15.78\n",
            "======================================================================================================================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=5 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data"
      ],
      "metadata": {
        "id": "Kjm7QvNyw5Vd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNj5UP1fHXR4",
        "outputId": "c666d499-92b7-4c67-fd04-8bd606522521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###DataViz"
      ],
      "metadata": {
        "id": "wDyw_vwEDCBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "class MultilingualDatasetAnalyzer:\n",
        "    \"\"\"\n",
        "    Analyze a multilingual dataset containing reviews, languages, and product categories.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, text_column: str = \"review_body\",\n",
        "                 lang_column: str = \"language\", category_column: str = \"product_category\") -> None:\n",
        "\n",
        "        self.df = df.copy()\n",
        "        self.text_column = text_column\n",
        "        self.lang_column = lang_column\n",
        "        self.category_column = category_column\n",
        "\n",
        "        self._validate_columns()\n",
        "\n",
        "    def _validate_columns(self) -> None:\n",
        "        \"\"\"Ensure required columns are present in the dataset.\"\"\"\n",
        "        required = {self.text_column, self.lang_column, self.category_column}\n",
        "        missing = required - set(self.df.columns)\n",
        "        if missing:\n",
        "            raise ValueError(f\"Missing required columns: {missing}\")\n",
        "\n",
        "    def compute_language_distribution(self) -> pd.DataFrame:\n",
        "        \"\"\"Compute count and percentage of reviews per language.\"\"\"\n",
        "        lang_stats = self.df[self.lang_column].value_counts().reset_index()\n",
        "        lang_stats.columns = [\"Language\", \"Count\"]\n",
        "        lang_stats[\"Percentage\"] = 100 * lang_stats[\"Count\"] / len(self.df)\n",
        "        return lang_stats\n",
        "\n",
        "    def unique_categories_per_language(self) -> pd.DataFrame:\n",
        "        \"\"\"List unique product categories for each language.\"\"\"\n",
        "        return (\n",
        "            self.df.groupby(self.lang_column)[self.category_column]\n",
        "            .apply(lambda x: sorted(x.dropna().unique().tolist()))\n",
        "            .reset_index(name=\"Unique Categories\")\n",
        "        )\n",
        "\n",
        "    def sample_review_per_language(self, random_state: int = 42) -> pd.DataFrame:\n",
        "        \"\"\"Sample one example review per language.\"\"\"\n",
        "        return (\n",
        "            self.df.groupby(self.lang_column)[self.text_column]\n",
        "            .apply(lambda x: x.dropna().sample(1, random_state=random_state).values[0]\n",
        "                   if not x.dropna().empty else \"N/A\")\n",
        "            .reset_index(name=\"Example Review\")\n",
        "        )\n",
        "\n",
        "    def plot_language_distribution(self) -> None:\n",
        "        \"\"\"Visualize the number of reviews per language.\"\"\"\n",
        "        stats = self.compute_language_distribution()\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.barplot(data=stats, x=\"Language\", y=\"Count\", palette=\"mako\")\n",
        "        plt.title(\"Number of Samples per Language\")\n",
        "        plt.ylabel(\"Review Count\")\n",
        "        plt.xlabel(\"Language\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def summarize(self) -> None:\n",
        "        \"\"\"Print summary statistics and samples.\"\"\"\n",
        "        print(\"Dataset Summary\")\n",
        "        print(f\"Total samples: {len(self.df)}\")\n",
        "        print(f\"Languages ({self.df[self.lang_column].nunique()}): {sorted(self.df[self.lang_column].unique())}\")\n",
        "\n",
        "        print(\"Language Distribution\")\n",
        "        print(self.compute_language_distribution().to_string(index=False))\n",
        "\n",
        "        print(\"Unique Categories per Language\")\n",
        "        print(self.unique_categories_per_language().to_string(index=False))\n",
        "\n",
        "        print(\"Example Review per Language\")\n",
        "        print(self.sample_review_per_language().to_string(index=False))\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Efrei_Datasets/train.csv\")\n",
        "analyzer = MultilingualDatasetAnalyzer(df, text_column=\"review_body\",\n",
        "                                        lang_column=\"language\",\n",
        "                                        category_column=\"product_category\")\n",
        "analyzer.summarize()\n",
        "# analyzer.plot_language_distribution()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhPmb99GIb1L",
        "outputId": "8bb04d98-c299-4aea-8647-2f2926f15c43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Summary\n",
            "Total samples: 1200000\n",
            "Languages (6): ['de', 'en', 'es', 'fr', 'ja', 'zh']\n",
            "Language Distribution\n",
            "Language  Count  Percentage\n",
            "      de 200000   16.666667\n",
            "      en 200000   16.666667\n",
            "      es 200000   16.666667\n",
            "      fr 200000   16.666667\n",
            "      ja 200000   16.666667\n",
            "      zh 200000   16.666667\n",
            "Unique Categories per Language\n",
            "language                                                                                                                                                                                                                                                                                                                                                                        Unique Categories\n",
            "      de [apparel, automotive, baby_product, beauty, book, camera, digital_ebook_purchase, digital_video_download, drugstore, electronics, furniture, grocery, home, home_improvement, industrial_supplies, jewelry, kitchen, lawn_and_garden, luggage, musical_instruments, office_product, other, pc, personal_care_appliances, pet_products, shoes, sports, toy, video_games, watch, wireless]\n",
            "      en [apparel, automotive, baby_product, beauty, book, camera, digital_ebook_purchase, digital_video_download, drugstore, electronics, furniture, grocery, home, home_improvement, industrial_supplies, jewelry, kitchen, lawn_and_garden, luggage, musical_instruments, office_product, other, pc, personal_care_appliances, pet_products, shoes, sports, toy, video_games, watch, wireless]\n",
            "      es                         [apparel, automotive, baby_product, beauty, book, camera, digital_ebook_purchase, drugstore, electronics, furniture, grocery, home, home_improvement, industrial_supplies, jewelry, kitchen, lawn_and_garden, luggage, musical_instruments, office_product, other, pc, personal_care_appliances, pet_products, shoes, sports, toy, video_games, watch, wireless]\n",
            "      fr                         [apparel, automotive, baby_product, beauty, book, camera, digital_ebook_purchase, drugstore, electronics, furniture, grocery, home, home_improvement, industrial_supplies, jewelry, kitchen, lawn_and_garden, luggage, musical_instruments, office_product, other, pc, personal_care_appliances, pet_products, shoes, sports, toy, video_games, watch, wireless]\n",
            "      ja                           [apparel, automotive, baby_product, beauty, book, camera, digital_ebook_purchase, digital_video_download, drugstore, electronics, furniture, grocery, home, home_improvement, industrial_supplies, jewelry, kitchen, lawn_and_garden, luggage, musical_instruments, office_product, other, pc, pet_products, shoes, sports, toy, video_games, watch, wireless]\n",
            "      zh                         [apparel, automotive, baby_product, beauty, book, camera, digital_ebook_purchase, drugstore, electronics, furniture, grocery, home, home_improvement, industrial_supplies, jewelry, kitchen, lawn_and_garden, luggage, musical_instruments, office_product, other, pc, personal_care_appliances, pet_products, shoes, sports, toy, video_games, watch, wireless]\n",
            "Example Review per Language\n",
            "language                                                                                                                        Example Review\n",
            "      de                                                                                              Ist ok ...blondierung quillt schnell auf\n",
            "      en                                                                   Not strong enough to run a small 120v vacuum cleaner, to clean car.\n",
            "      es                                                 Mini usb cable de carga defectuoso por lo cual se estropearon los usb de las baterias\n",
            "      fr attention je pensais que c'était de vrais sequins. ce n'est pas le cas mais les enfants seront ravies tout de même car bien brillant.\n",
            "      ja             ハロウィン用に購入しました。ピンがついたふかふかの耳でかわいいけれど、つけた時に安定感がなく難しい。付属のカチューシャにピンを差し込んで併用してもどこか明後日を向いてしまう感じ。使いづらいけれど、かわいいので何とか工夫して使っていきたいです。\n",
            "      zh                                                                            物流，配货非常不满意，速度超慢，希望有所改进。以前在亚马逊买过东西，那时物流比现在给力，不知道为什么现在还越来越差了\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Dataset"
      ],
      "metadata": {
        "id": "AWDBkwGhHOyW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "from typing import List, Dict, Tuple\n",
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "\n",
        "class MultilingualDomainDataset(Dataset):\n",
        "    LANGUAGES = ['en', 'fr', 'de']\n",
        "    DOMAIN_MAP = {\n",
        "        'en': [1, 0, 0],\n",
        "        'fr': [0, 1, 0],\n",
        "        'de': [0, 0, 1]\n",
        "    }\n",
        "\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer_name: str, label2id: Dict[str, int],\n",
        "                 text_column: str = \"review_body\", lang_column: str = \"language\",\n",
        "                 label_column: str = \"product_category\", max_length: int = 128):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
        "        self.label2id = label2id\n",
        "        self.text_column = text_column\n",
        "        self.lang_column = lang_column\n",
        "        self.label_column = label_column\n",
        "        self.max_length = max_length\n",
        "        self.vocab_size = self.tokenizer.vocab_size\n",
        "\n",
        "        # desired languages\n",
        "        self.samples = [\n",
        "            (row[text_column], row[lang_column], row[label_column])\n",
        "            for _, row in df.iterrows()\n",
        "            if row[lang_column] in self.LANGUAGES and pd.notna(row[label_column])\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx) -> Dict[str, torch.Tensor]:\n",
        "        text, lang, label = self.samples[idx]\n",
        "        encoded = self.tokenizer(text, padding=\"max_length\", truncation=True,\n",
        "                                 max_length=self.max_length, return_tensors=\"pt\")\n",
        "\n",
        "        seq_len = encoded[\"input_ids\"].shape[1]\n",
        "        domain_vector = torch.tensor(self.DOMAIN_MAP[lang], dtype=torch.float)\n",
        "        domain_matrix = domain_vector.repeat(seq_len, 1)\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": encoded[\"input_ids\"].squeeze(0),           # (seq_len)\n",
        "            \"attention_mask\": encoded[\"attention_mask\"].squeeze(0), # (seq_len)\n",
        "            \"domain_embedding\": domain_matrix,                      # (seq_len, 3)\n",
        "            \"language\": lang,\n",
        "            \"label\": torch.tensor(self.label2id[label], dtype=torch.long)\n",
        "\n",
        "         }\n",
        "    def get_vocab_size(self):\n",
        "        return self.vocab_size\n",
        "\n",
        "\n",
        "def multilingual_batch_sampler(dataset: MultilingualDomainDataset, batch_size: int) -> List[List[int]]:\n",
        "    indices_by_lang = defaultdict(list)\n",
        "    for idx, (_, lang, _) in enumerate(dataset.samples):\n",
        "        indices_by_lang[lang].append(idx)\n",
        "\n",
        "    for lang in indices_by_lang:\n",
        "        random.shuffle(indices_by_lang[lang])\n",
        "\n",
        "    all_batches = []\n",
        "    for lang, indices in indices_by_lang.items():\n",
        "        for i in range(0, len(indices), batch_size):\n",
        "            batch = indices[i:i + batch_size]\n",
        "            if len(batch) == batch_size:\n",
        "                all_batches.append(batch)\n",
        "\n",
        "    random.shuffle(all_batches)\n",
        "    return all_batches\n",
        "\n",
        "\n",
        "def multilingual_collate_fn(batch: List[Dict]) -> Dict[str, torch.Tensor]:\n",
        "    return {\n",
        "        \"input_ids\": torch.stack([item[\"input_ids\"] for item in batch]),\n",
        "        \"attention_mask\": torch.stack([item[\"attention_mask\"] for item in batch]),\n",
        "        \"domain_embedding\": torch.stack([item[\"domain_embedding\"] for item in batch]),\n",
        "        \"labels\": torch.stack([item[\"label\"] for item in batch]),\n",
        "        \"language\": batch[0][\"language\"]\n",
        "    }\n",
        "\n",
        "\n",
        "def create_label_mapping(*dfs: List[pd.DataFrame], label_column: str = \"product_category\") -> Dict[str, int]:\n",
        "    labels = set()\n",
        "    for df in dfs:\n",
        "        labels.update(df[label_column].dropna().unique())\n",
        "    return {label: idx for idx, label in enumerate(sorted(labels))}\n",
        "\n",
        "\n",
        "def build_dataloaders(train_path: str, val_path: str, test_path: str,\n",
        "                      tokenizer_name: str, batch_size: int = 16, max_length: int = 128):\n",
        "\n",
        "    df_train = pd.read_csv(train_path)\n",
        "    df_val = pd.read_csv(val_path)\n",
        "    df_test = pd.read_csv(test_path)\n",
        "\n",
        "\n",
        "    label2id = create_label_mapping(df_train, df_val, df_test)\n",
        "\n",
        "\n",
        "    train_dataset = MultilingualDomainDataset(df_train, tokenizer_name, label2id, max_length=max_length)\n",
        "    val_dataset = MultilingualDomainDataset(df_val, tokenizer_name, label2id, max_length=max_length)\n",
        "    test_dataset = MultilingualDomainDataset(df_test, tokenizer_name, label2id, max_length=max_length)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset,\n",
        "        batch_sampler=multilingual_batch_sampler(train_dataset, batch_size),\n",
        "        collate_fn=multilingual_collate_fn\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset,\n",
        "        batch_sampler=multilingual_batch_sampler(val_dataset, batch_size),\n",
        "        collate_fn=multilingual_collate_fn\n",
        "    )\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_sampler=multilingual_batch_sampler(test_dataset, batch_size),\n",
        "        collate_fn=multilingual_collate_fn\n",
        "    )\n",
        "    vocab_size = train_dataset.get_vocab_size()\n",
        "    print(f\"Vocab size: {vocab_size}\")\n",
        "\n",
        "    return train_loader, val_loader, test_loader, label2id,vocab_size"
      ],
      "metadata": {
        "id": "jQ7iRmDjME2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, val_loader, test_loader, label2id,vocab_size = build_dataloaders(\n",
        "    train_path=\"/content/drive/MyDrive/Efrei_Datasets/train.csv\",\n",
        "    val_path=\"/content/drive/MyDrive/Efrei_Datasets/validation.csv\",\n",
        "    test_path=\"/content/drive/MyDrive/Efrei_Datasets/test.csv\",\n",
        "    tokenizer_name=\"bert-base-multilingual-cased\",\n",
        "    batch_size=16,\n",
        "    max_length=128\n",
        ")"
      ],
      "metadata": {
        "id": "ThJC9jU414B5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "910f995a18bb4d7ab8a926676c08f978",
            "d67306189eb5486ba981ed8423dff2cb",
            "bc520cc9762b49e58530e292b7b7bb56",
            "0dedc21ba217431dbcbf4f055ca4dfc5",
            "1f042fa3434744229abfef51d29b3234",
            "7263a034ba5041dabad0029237b3517a",
            "45412af024f446caa0dea9fdfbaa3172",
            "2379f7a484bd4862b61e17ff3ccb7954",
            "aced003b8a6f4bdfa820f8936fa3cbda",
            "e9db3ac5a4e14647aa88d0a82fa479c8",
            "22ec881b725f40b4a4b305807c540d70",
            "083d83e70fac41e4919ec50d3f3128d7",
            "95e2fe0240214f6db8090a3365360391",
            "1e1e3f90e3bb45b787f9bb19ada0de04",
            "e29831df898d4d0289f8b6478a3f5480",
            "c4c5cf08de144023b1a7224b1ab004a9",
            "df1542299633409db9317c1d4f0d9652",
            "149347d26a924312baf1206f3bb01f0c",
            "bed83d4ff29e45c688b379ba1955c2b7",
            "a23b708a0c24495688e8a387debedbb0",
            "a285270f74b54da5a2afd0da955462c7",
            "eedbd7ee754d4844a9b13debe84f04a1",
            "0b449615c3224f7faf45f9fa307f00e4",
            "d75319594725400cb0a78161e7e924b8",
            "0e7ce4ef0ee04609b124159ccb0ae5f0",
            "f32ead801e484a4bbbff14fdb649640f",
            "f0a713073db84971a76813cbd450809b",
            "f2be68db401143ca94459a62d03bf68e",
            "62fae1f6da9b463fbcccbb3b8950477a",
            "2340c95fb0c948bdb2a98de44ec6b0ea",
            "bd106d03b4104839b02f68c330e934f0",
            "afbe97b551654d04a816ff5c899b3cef",
            "0d6353ec3fb0493dbe0821cbddc7bb10",
            "a58e5427079c4c67a344b26337c3c227",
            "c86272b0208e42d9bbce9d14c6f64875",
            "168e77ae27b147f39034b8dfadec951d",
            "76258b2062b44793bd4f83cd73999466",
            "88242159bb734ab49cb4d02d6717be41",
            "2d0aae2bdd5648aca100fcbbfc0c7832",
            "f0b3566a08b2413dab305c06211390c1",
            "5991c0e35d56449aae9167e26455593b",
            "ac1cfe6d12cb4ce6bb28c0cc114f453d",
            "06df3b27bc04475fbbafc67b877a2834",
            "3bf0fd1e4b7b4658ad56eab175539d0c"
          ]
        },
        "outputId": "57ef97bf-f34f-423e-d49c-42f686d0a48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "910f995a18bb4d7ab8a926676c08f978"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "083d83e70fac41e4919ec50d3f3128d7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b449615c3224f7faf45f9fa307f00e4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a58e5427079c4c67a344b26337c3c227"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 119547\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_loader))\n",
        "print(batch[\"input_ids\"])        # (B, seq_len)\n",
        "print(batch[\"domain_embedding\"].shape) # (B, seq_len, 3)\n",
        "print(batch[\"labels\"])                 # (B,)\n",
        "print(batch[\"language\"])               # string: en / fr / de\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzI3CcCU2POT",
        "outputId": "5322667d-9464-4c95-eb8a-df0dc9a456e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  101, 27448, 10614,  ...,     0,     0,     0],\n",
            "        [  101, 27448, 10614,  ...,     0,     0,     0],\n",
            "        [  101, 91985, 22873,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  101, 39007, 17215,  ..., 10109, 10813,   102],\n",
            "        [  101, 30135, 10426,  ...,     0,     0,     0],\n",
            "        [  101, 13796, 74619,  ...,     0,     0,     0]])\n",
            "torch.Size([16, 128, 3])\n",
            "tensor([ 6,  0, 27, 16,  2,  8,  4, 26,  0,  0, 17, 27, 13,  9, 26, 13])\n",
            "fr\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trainer"
      ],
      "metadata": {
        "id": "R2efEfD7C-6u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    device,\n",
        "    num_epochs=10,\n",
        "    model_name=\"model_with_domain_context\",\n",
        "    env=\"colab\"\n",
        "):\n",
        "    model.to(device)\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Epoch: \",epoch)\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        # Progress bar for training batches\n",
        "        train_iter = tqdm(train_loader, desc=f\"Epoch {epoch+1} Training\", leave=False)\n",
        "        for batch in train_iter:\n",
        "            x = batch['input_ids'].to(device)\n",
        "            m = batch['domain_embedding'].to(device)\n",
        "            y = batch['labels'].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(x, m)\n",
        "            loss = criterion(outputs, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "            train_iter.set_postfix(loss=total_loss/(total//y.size(0)), accuracy=100.*correct/total)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "        val_iter = tqdm(val_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False)\n",
        "        with torch.no_grad():\n",
        "            for batch in val_iter:\n",
        "                x = batch['input_ids'].to(device)\n",
        "                m = batch['domain_embedding'].to(device)\n",
        "                y = batch['labels'].to(device)\n",
        "\n",
        "                outputs = model(x, m)\n",
        "                loss = criterion(outputs, y)\n",
        "                val_loss += loss.item()\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                val_correct += (preds == y).sum().item()\n",
        "                val_total += y.size(0)\n",
        "\n",
        "                val_iter.set_postfix(val_loss=val_loss/(val_total//y.size(0)), val_accuracy=100.*val_correct/val_total)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss={total_loss/len(train_loader):.4f}, \"\n",
        "              f\"Train Acc={100.*correct/total:.2f}%, \"\n",
        "              f\"Val Loss={val_loss/len(val_loader):.4f}, \"\n",
        "              f\"Val Acc={100.*val_correct/val_total:.2f}%\")\n",
        "    if env == \"kaggle\":\n",
        "        model_path = f\"/kaggle/working/{model_name}.pt\"\n",
        "    else:\n",
        "        model_path = f\"/content/{model_name}.pt\"\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "    print(f\"Model saved to {model_path}\")\n",
        "\n",
        "def test_model(model, test_loader, criterion, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    test_correct = 0\n",
        "    test_total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
        "            x = batch['input_ids'].to(device)\n",
        "            m = batch['domain_embedding'].to(device)\n",
        "            y = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(x, m)\n",
        "            loss = criterion(outputs, y)\n",
        "            test_loss += loss.item()\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            test_correct += (preds == y).sum().item()\n",
        "            test_total += y.size(0)\n",
        "\n",
        "    print(f\"\\nTest Loss = {test_loss/len(test_loader):.4f}, \"\n",
        "          f\"Test Accuracy = {100. * test_correct / test_total:.2f}%\")"
      ],
      "metadata": {
        "id": "Yjl_G5s-Vkp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_domain_context = DomainAwareTransformerEncoder(\n",
        "    num_domains=6,\n",
        "    input_dim=64,\n",
        "    hidden_dim=128,\n",
        "    domain_embed_dim=1,\n",
        "    num_classes=31,\n",
        "    vocab_size=vocab_size,\n",
        "    inject_domain_bias=True,\n",
        "    use_attention_fusion=True\n",
        ")\n",
        "# model_without_domain_context = DomainAwareTransformerEncoder(\n",
        "#     num_domains=6,\n",
        "#     input_dim=64,\n",
        "#     hidden_dim=128,\n",
        "#     domain_embed_dim=1,\n",
        "#     num_classes=31,\n",
        "#     vocab_size=vocab_size,\n",
        "#     inject_domain_bias=False\n",
        "# )\n",
        "optimizer_with_domain_context  = torch.optim.Adam(model_with_domain_context.parameters(), lr=1e-4)\n",
        "# optimizer_without_domain_context  = torch.optim.Adam(model_without_domain_context.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "train_model(model_with_domain_context, train_loader, val_loader, optimizer_with_domain_context, criterion, device, num_epochs=15)\n",
        "# train_model(model_without_domain_context, train_loader, val_loader, optimizer_without_domain_context, criterion, device, num_epochs=15,model_name=\"model_without_domain_context\")\n",
        "test_model(model_with_domain_context, test_loader, criterion, device)\n",
        "# with domain context, without attention fusion Test Loss = 1.9987, Test Accuracy = 42.30%\n",
        "# test_model(model_without_domain_context, test_loader, criterion, device)\n",
        "# without context Test Loss = 2.0064, Test Accuracy = 42.16%\n"
      ],
      "metadata": {
        "id": "IJTdoMl23tfR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "b31fecea-f625-496a-ff5a-4e364e20e3dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2d05b6e49b91>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_with_domain_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_with_domain_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_without_domain_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_without_domain_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model_without_domain_context\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_with_domain_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-27aa8b59897a>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, device, num_epochs, model_name, env)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-c3212d043a3b>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, m)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0menriched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_proj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0menc\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menriched\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ed98efa78a78>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \"\"\"\n\u001b[1;32m     39\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             output = mod(\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0msrc_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    918\u001b[0m             x = self.norm1(\n\u001b[1;32m    919\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sa_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_key_padding_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_causal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_causal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m             )\n\u001b[1;32m    922\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\u001b[0m in \u001b[0;36m_sa_block\u001b[0;34m(self, x, attn_mask, key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0mis_causal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     ) -> Tensor:\n\u001b[0;32m--> 934\u001b[0;31m         x = self.self_attn(\n\u001b[0m\u001b[1;32m    935\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1371\u001b[0m             )\n\u001b[1;32m   1372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1374\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6228\u001b[0m             \u001b[0min_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6229\u001b[0m         ), \"use_separate_proj_weight is False but in_proj_weight is None\"\n\u001b[0;32m-> 6230\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_in_projection_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6232\u001b[0m         assert (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   5612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mq\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5613\u001b[0m             \u001b[0;31m# self-attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5614\u001b[0;31m             \u001b[0mproj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5615\u001b[0m             \u001b[0;31m# reshape to 3, E and not E, 3 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5616\u001b[0m             proj = (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}